<html>
<head>
<title>Fast Temporal Activity Proposals for Efficient Detection of Human Actions in Untrimmed Videos</title>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="jquery.mlens-1.0.min.js"></script>

<style>
body
{
    font-family : Arial;
	background-color : #EFEFEF;
}
.content
{
    width : 800px;
    padding : 25px 50px;
    margin : 25px auto;
    background-color : #fff;
    box-shadow: 0px 0px 10px #999;
    border-radius: 15px; 
}

.contentblock
{
    width : 950px;
    margin : 0 auto;
    padding : 0;
    border-spacing : 25px 0;
}

.contentblock td
{
    background-color : #fff;
    padding : 25px 50px;
    vertical-align : top;
    box-shadow: 0px 0px 10px #999;
    border-radius: 15px; 
}

a, a:visited
{
    color : blue;
}

#authors
{
    text-align : center;
    margin-bottom : 20px;
}

#conference
{
    text-align : center;
    margin-bottom : 20px;
    font-style : italic;
}

#authors a 
{
    margin : 0 10px;
}

h1
{
    text-align : center;
    font-family : Arial;
    font-size : 30px;
}

code
{
	display : block;
	padding : 10px;
	margin : 10px 10px;
}
p code
{
    display : inline;
    padding : 0;
    margin : 0;
}
#teasers
{
    margin : 0 auto;    
}

#teasers td
{
    margin : 0 auto;
    text-align : center;
    padding : 5px;
}

#teasers img
{
    width : 250px; 
}

#results img
{
    width : 133px;
}

#seeintodark {
    margin : 0 auto;
}

#sift 
{
    margin : 0 auto;
}

#sift img
{
    width : 250px;
}

.downloadpaper 
{
    padding-left : 20px;
    float : right;
    text-align : center;
}

.downloadpaper a 
{
    font-weight : bold;
    text-align : center;
}

#demoframe
{
    border : 0;
    padding : 0;
    margin : 0;
    width : 100%;
    height : 340px;
}

#feedbackform
{
    border : 1px solid #ccc;
    margin : 0 auto;
    border-radius : 15px;
}

#eyeglass {
    height : 530px;
}

#eyeglass #wrapper {
    position: relative;
    height: auto;
    margin: 0 auto;
    float: left;
    width : 800px;
}


</style>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-56208223-1', 'auto');
  ga('send', 'pageview');

</script>

</head>

<body>

<div class="content">
<h1>Fast Temporal Activity Proposals for Efficitent Detection of Human Actions in Untrimmed Videos</h1>
<p id="authors">
<a href="http://www.cabaf.net">Fabian Caba Heilbron</a>
<a href="http://www.niebles.net">Juan Carlos Niebles</a>
<a href="http://www.bernardghanem.com">Bernard Ghanem</a><br>
KAUST, Stanford University
</p>

<p id="conference">
<a href="http://cvpr2016.thecvf.com/">CVPR 2016</a>
</p>

<h2> Summary </h2>
<p>
In many large-scale video analysis scenarios, one is interested in localizing and recognizing human activities that occur in short temporal intervals within long untrimmed videos. Current approaches for activity detection still struggle to handle large-scale video collections and the task remains relatively unexplored. This is in part due to the computational complexity of current action recognition approaches and the lack of a method that proposes fewer intervals in the video, where activity processing can be focused. In this paper, we introduce a proposal method that aims to recover temporal segments containing actions in untrimmed videos. Building on techniques for learning sparse dictionaries, we introduce a learning framework to represent and retrieve activity proposals. We demonstrate the capabilities of our method in not only producing high quality proposals but also in its efficiency. Finally, we show the positive impact our method has on recognition performance when it is used for action detection, while running at 10FPS.
</p>
<img src="img/pull_figure.png" class="img-responsive"></img>


<br clear="all">

<h4>Resources:</h4>
<li><span>Download our CVPR 2016 <strong> <a href="paper/temporal_proposals.pdf">Paper</a>. </strong></br></span></li>
<li><span>Check out our <strong> <a href="poster/temporal_proposals.pdf">Poster presentation!</a> </strong></br></span></li>
<li><span><strong>Code will be available soon!</strong> </strong></span></li>

<!--
can be cloned from <strong><a href="https://github.com/cabaf/actioncue.git">Here!</a></strong></span></li>
-->

</div>

<!--<table class="contentblock">
<tr>
<td style="width:300px;">

<h2>Resources</h2>
<span>Download our ACCV 2014 <strong> <a href="paper/actioncue.pdf">Paper</a>. </strong></br></span>
<span>Check out our <strong> <a href="poster/actioncue.pdf">Poster presentation!</a> </strong></br></span>
<span><strong>Code</strong> can be cloned from <strong><a href="https://github.com/cabaf/actioncue.git">Here!</a></strong></span>

</td>
<td style="width:300px;">

<h2>Acknowledgment</h2>
<p> <small>Research reported in this publication was supported by
competitive research funding from King Abdullah University of Science and
Technology (KAUST). F.C.H. was also supported by a COLCIENCIAS Young
Scientist and Innovator Fellowship. J.C.N. is supported by a Microsoft Research
Faculty Fellowship.</small><p>
</td>
</tr>
</table>
-->
<div class="content" id="references">
<h2>Acknowledgment</h2>
<p>
Research in this publication was supported by the King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research, the Stanford AI Lab Toyota Center for Artificial Intelligence Research, and a Google Faculty Research Award (2015).
<p>

<h2>References</h2>

<p>If you use any of this work material in your research, please cite our CVPR 2016 paper:</p>

<code>
@article{caba2016_proposals,<br>
&nbsp;&nbsp;title={{Fast Temporal Activity Proposals for Efficitent Detection of Human Actions in Untrimmed Videos}},<br>
&nbsp;&nbsp;author={Caba Heilbron, Fabian and Niebles, Juan Carlos, and Ghanem, Bernard},<br>
&nbsp;&nbsp;journal={CVPR},<br>
&nbsp;&nbsp;year={2016}<br>
}
</code>

</div>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
</body>
</html>
